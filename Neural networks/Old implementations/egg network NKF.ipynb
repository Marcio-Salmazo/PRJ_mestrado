{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential  # Modelo sequencial\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import os \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dataTrain: (4080, 512, 512, 3)\n",
      "Shape dataTest: (1020, 512, 512, 3)\n",
      "Shape classTrain: (4080, 1)\n",
      "Shape classTest: (1020, 1)\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "    Carregando a pasta de imagens (Dataset dos ovos)\n",
    "    * A função glob encontra todos os nomes de caminhos que correspondem a um padrão \n",
    "      especificado de acordo com as regras usadas pelo shell Unix\n",
    "\n",
    "    * Para cada um dos arquivos encontrados é feita a leitura\n",
    "      do arquivo .jpg (imagem), as imagens lidas são armazenadas\n",
    "      na lista 'data'\n",
    "'''\n",
    "\n",
    "img_dir = \"C:/Users/marci/Desktop/Projeto mestrado/CNN Egg application/Egg Dataset\"\n",
    "data_path = os.path.join(img_dir,'*g') \n",
    "\n",
    "folder = glob.glob(data_path) \n",
    "data = [] \n",
    "for files in folder: \n",
    "    img = cv2.imread(files) \n",
    "    data.append(img) \n",
    "\n",
    "eggData = np.array(data)\n",
    "eggClass = pd.read_csv(\"RealData.csv\")\n",
    "\n",
    "dataTrain, dataTest = train_test_split(eggData, test_size=0.2) \n",
    "classTrain, classTest = train_test_split(eggClass, test_size=0.2)\n",
    "\n",
    "print('Shape dataTrain:', dataTrain.shape)\n",
    "print('Shape dataTest:', dataTest.shape)\n",
    "print('Shape classTrain:', classTrain.shape)\n",
    "print('Shape classTest:', classTest.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Alterando o tipo dos dados para float32 a fim de aplicar \n",
    "    a normalização futuramente\n",
    "'''\n",
    "\n",
    "dataTrain = dataTrain.astype('float32')\n",
    "dataTest = dataTest.astype('float32')\n",
    "\n",
    "'''\n",
    "    Realizando a normalização (min/max normalization) a fim de que os valores dos pixels estejam\n",
    "    entre 0 e 1, tornando o processamento mais eficiente\n",
    "    obs: 255 é o valor máximo do pixel\n",
    "'''\n",
    "\n",
    "dataTrain /= 255\n",
    "dataTest /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "   Definição da rede neural convolucional\n",
    "\n",
    "    * Criação da cnn no modelo sequencial (sequencia de layers)\n",
    "    * Criação de duas camadas de convolução com função de ativação Relu, \n",
    "      seguidas pelos processos de normalização dos mapas de características e max Pooling.\n",
    "      O processo de flattening é adicionado ao final das camadas. \n",
    "'''\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), input_shape = (512, 512, 3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "'''\n",
    "    * Adição das hidden Layers\n",
    "    * Aplicação da operação de dropout às saídas \n",
    "        Busca zerar uma determinada quantidade de entradas \n",
    "        a fim de otimizar o sistema e reduzir o overfitting\n",
    "    * Adição da camada de saída, utilizando a sigmóide como função de ativação\n",
    "        A sigmóide é utilzada em classificações binárias\n",
    "        OBS -> units = 1 indica que há apenas uma unidade de saída para\n",
    "        a classificação binária\n",
    "'''\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "'''\n",
    "    * Compilação da rede neural\n",
    "        OBS: Para a classificação binária, a função de perda será definida \n",
    "        por 'binary_crossentropy'. Para a classificação em múltiplas classes\n",
    "        é necessário utilizar o 'categorical_crossentropy'\n",
    "'''\n",
    "\n",
    "classifier.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "255/255 [==============================] - 408s 2s/step - loss: 6.7609 - accuracy: 0.6980 - val_loss: 2.2795 - val_accuracy: 0.7127\n",
      "Epoch 2/30\n",
      "255/255 [==============================] - 377s 1s/step - loss: 0.5999 - accuracy: 0.7353 - val_loss: 0.8851 - val_accuracy: 0.7127\n",
      "Epoch 3/30\n",
      "255/255 [==============================] - 374s 1s/step - loss: 0.5817 - accuracy: 0.7353 - val_loss: 0.5997 - val_accuracy: 0.7127\n",
      "Epoch 4/30\n",
      "255/255 [==============================] - 372s 1s/step - loss: 0.5799 - accuracy: 0.7353 - val_loss: 0.6002 - val_accuracy: 0.7127\n",
      "Epoch 5/30\n",
      "255/255 [==============================] - 372s 1s/step - loss: 0.5791 - accuracy: 0.7353 - val_loss: 0.6008 - val_accuracy: 0.7127\n",
      "Epoch 6/30\n",
      "255/255 [==============================] - 372s 1s/step - loss: 0.5788 - accuracy: 0.7353 - val_loss: 0.6011 - val_accuracy: 0.7127\n",
      "Epoch 7/30\n",
      "255/255 [==============================] - 373s 1s/step - loss: 0.5781 - accuracy: 0.7353 - val_loss: 0.6012 - val_accuracy: 0.7127\n",
      "Epoch 8/30\n",
      "255/255 [==============================] - 371s 1s/step - loss: 0.5791 - accuracy: 0.7353 - val_loss: 0.6011 - val_accuracy: 0.7127\n",
      "Epoch 9/30\n",
      "255/255 [==============================] - 375s 1s/step - loss: 0.5781 - accuracy: 0.7353 - val_loss: 0.6009 - val_accuracy: 0.7127\n",
      "Epoch 10/30\n",
      "255/255 [==============================] - 372s 1s/step - loss: 0.5785 - accuracy: 0.7353 - val_loss: 0.6009 - val_accuracy: 0.7127\n",
      "Epoch 11/30\n",
      "255/255 [==============================] - 371s 1s/step - loss: 0.5796 - accuracy: 0.7353 - val_loss: 0.6008 - val_accuracy: 0.7127\n",
      "Epoch 12/30\n",
      "255/255 [==============================] - 372s 1s/step - loss: 0.5783 - accuracy: 0.7353 - val_loss: 0.6012 - val_accuracy: 0.7127\n",
      "Epoch 13/30\n",
      "255/255 [==============================] - 374s 1s/step - loss: 0.5792 - accuracy: 0.7353 - val_loss: 0.6010 - val_accuracy: 0.7127\n",
      "Epoch 14/30\n",
      "255/255 [==============================] - 371s 1s/step - loss: 0.5783 - accuracy: 0.7353 - val_loss: 0.6009 - val_accuracy: 0.7127\n",
      "Epoch 15/30\n",
      "255/255 [==============================] - 370s 1s/step - loss: 0.5788 - accuracy: 0.7353 - val_loss: 0.6010 - val_accuracy: 0.7127\n",
      "Epoch 16/30\n",
      "255/255 [==============================] - 376s 1s/step - loss: 0.5786 - accuracy: 0.7353 - val_loss: 0.6009 - val_accuracy: 0.7127\n",
      "Epoch 17/30\n",
      "255/255 [==============================] - 378s 1s/step - loss: 0.5790 - accuracy: 0.7353 - val_loss: 0.6006 - val_accuracy: 0.7127\n",
      "Epoch 18/30\n",
      "255/255 [==============================] - 377s 1s/step - loss: 0.5787 - accuracy: 0.7353 - val_loss: 0.6006 - val_accuracy: 0.7127\n",
      "Epoch 19/30\n",
      "255/255 [==============================] - 378s 1s/step - loss: 0.5785 - accuracy: 0.7353 - val_loss: 0.6010 - val_accuracy: 0.7127\n",
      "Epoch 20/30\n",
      "255/255 [==============================] - 377s 1s/step - loss: 0.5780 - accuracy: 0.7353 - val_loss: 0.6008 - val_accuracy: 0.7127\n",
      "Epoch 21/30\n",
      "255/255 [==============================] - 375s 1s/step - loss: 0.5781 - accuracy: 0.7353 - val_loss: 0.6007 - val_accuracy: 0.7127\n",
      "Epoch 22/30\n",
      "255/255 [==============================] - 371s 1s/step - loss: 0.5780 - accuracy: 0.7353 - val_loss: 0.6007 - val_accuracy: 0.7127\n",
      "Epoch 23/30\n",
      "255/255 [==============================] - 372s 1s/step - loss: 0.5786 - accuracy: 0.7353 - val_loss: 0.6009 - val_accuracy: 0.7127\n",
      "Epoch 24/30\n",
      "255/255 [==============================] - 372s 1s/step - loss: 0.5795 - accuracy: 0.7353 - val_loss: 0.6001 - val_accuracy: 0.7127\n",
      "Epoch 25/30\n",
      "255/255 [==============================] - 373s 1s/step - loss: 0.5790 - accuracy: 0.7353 - val_loss: 0.6009 - val_accuracy: 0.7127\n",
      "Epoch 26/30\n",
      "255/255 [==============================] - 372s 1s/step - loss: 0.5786 - accuracy: 0.7353 - val_loss: 0.6002 - val_accuracy: 0.7127\n",
      "Epoch 27/30\n",
      "255/255 [==============================] - 372s 1s/step - loss: 0.5784 - accuracy: 0.7353 - val_loss: 0.6015 - val_accuracy: 0.7127\n",
      "Epoch 28/30\n",
      "255/255 [==============================] - 372s 1s/step - loss: 0.5789 - accuracy: 0.7353 - val_loss: 0.6012 - val_accuracy: 0.7127\n",
      "Epoch 29/30\n",
      "255/255 [==============================] - 371s 1s/step - loss: 0.5786 - accuracy: 0.7353 - val_loss: 0.6008 - val_accuracy: 0.7127\n",
      "Epoch 30/30\n",
      "255/255 [==============================] - 372s 1s/step - loss: 0.5784 - accuracy: 0.7353 - val_loss: 0.6008 - val_accuracy: 0.7127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1defc9205d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    Etapa de treinamento da rede neural. É importante que a função 'fit_generator' está sendo\n",
    "    utilizada ao invés da função 'fit' uma vez que ela suporta o processo de augmentation, contudo\n",
    "    tal função está em processo de depreciação, uma vez que em versões mais atuais, a função 'fit' \n",
    "    também suporta.\n",
    "\n",
    "    Explicação dos parâmetros:\n",
    "\n",
    "    * trainDatabase -> Dados para treino (após a augmentation)\n",
    "    * steps_per_epoch -> Número total de etapas (lotes de amostras) a serem produzidas \n",
    "                         pelo gerador antes de declarar uma época concluída e iniciar a próxima época.\n",
    "                         É importante citar que o valor ideal para este parâmetro se dá pela quantidade \n",
    "                         total de imagens para treinamento (caso haja um alto poder de processamento) ou\n",
    "                         pelo total de amostras dividido pel valor do batch_size (caso haja um baixo \n",
    "                         poder de processamento)\n",
    "    * epochs -> Epocas de treinamento da rede\n",
    "    * validation_data -> Dados para a validação (após a augmentation)\n",
    "    * validation_steps -> Possui o mesmo princípio do 'steps_per_epoch', porém levando em \n",
    "                          consideração a etapa de validação. O valor ideal para este parâmetro \n",
    "                          se dá pelo total de amostras dividido pel valor do batch_size\n",
    "'''\n",
    "\n",
    "classifier.fit(dataTrain, classTrain, batch_size = 16, epochs = 30, validation_data = (dataTest, classTest))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
