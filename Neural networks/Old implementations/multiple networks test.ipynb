{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras import layers, models, optimizers, losses\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import os \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100\n",
      "(5100, 1)\n"
     ]
    }
   ],
   "source": [
    "# CARREGAMENTO DOS DATASETS\n",
    "\n",
    "''' \n",
    "    Carregando a pasta de imagens (Dataset dos ovos)\n",
    "    * A função glob encontra todos os nomes de caminhos que correspondem a um padrão \n",
    "      especificado de acordo com as regras usadas pelo shell Unix\n",
    "\n",
    "    * Para cada um dos arquivos encontrados é feita a leitura\n",
    "      do arquivo .jpg (imagem), as imagens lidas são armazenadas\n",
    "      na lista 'data'\n",
    "'''\n",
    "\n",
    "#img_dir = \"C:/Users/marci/Desktop/Projeto mestrado/CNN Egg application/Egg Dataset\"\n",
    "img_dir = \"C:/Users/marci/Desktop/Arquivos/PRJ_mestrado/CNN Egg application/Egg Dataset\"\n",
    "data_path = os.path.join(img_dir,'*g') \n",
    "\n",
    "folder = glob.glob(data_path) \n",
    "data = [] \n",
    "for files in folder: \n",
    "    img = cv2.imread(files) \n",
    "    data.append(img) \n",
    "\n",
    "'''   \n",
    "    Carregando e tratando o arquivo CSV\n",
    "'''\n",
    "eggClass = pd.read_csv(\"RealData.csv\")\n",
    "cList = eggClass.to_numpy()\n",
    "\n",
    "print(len(data))\n",
    "print(cList.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img train 4080\n",
      "img test 1020\n",
      "class train 4080\n",
      "class test 1020\n"
     ]
    }
   ],
   "source": [
    "# Dataset Completo\n",
    "# Comentar seção caso não seja necessário\n",
    "\n",
    "ind = np.arange(len(data))\n",
    "train, test = train_test_split(ind, test_size=0.2, random_state=42)\n",
    "\n",
    "#\n",
    "dataTrain = []\n",
    "dataTest = []\n",
    "classTrain = []\n",
    "classTest = []\n",
    "\n",
    "#\n",
    "for i in range(len(train)):\n",
    "\n",
    "    dataTrain.append(data[train[i]])\n",
    "    classTrain.append(cList[train[i]])\n",
    "\n",
    "for j in range(len(test)):\n",
    "\n",
    "    dataTest.append(data[test[j]])\n",
    "    classTest.append(cList[test[j]])\n",
    "\n",
    "#\n",
    "dataTrain = np.array(dataTrain)\n",
    "dataTest = np.array(dataTest)\n",
    "classTrain = np.array(classTrain)\n",
    "classTest = np.array(classTest)\n",
    "\n",
    "print('img train', len(dataTrain))\n",
    "print('img test', len(dataTest))\n",
    "print('class train', len(classTrain))\n",
    "print('class test', len(classTest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "del cList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Alterando o tipo dos dados para float32 a fim de aplicar \n",
    "    a normalização futuramente\n",
    "'''\n",
    "\n",
    "dataTrain = dataTrain.astype('float32')\n",
    "dataTest = dataTest.astype('float32')\n",
    "\n",
    "'''\n",
    "    Realizando a normalização (min/max normalization) a fim de que os valores dos pixels estejam\n",
    "    entre 0 e 1, tornando o processamento mais eficiente\n",
    "    obs: 255 é o valor máximo do pixel\n",
    "'''\n",
    "\n",
    "dataTrain /= 255\n",
    "dataTest /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marci\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# SHALLOW NETWORK\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), input_shape = (512, 512, 3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALEXNET\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(96, (11, 11), strides=4, activation='relu', input_shape = (512, 512, 3), padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    \n",
    "model.add(Conv2D(256, (5, 5), strides=1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    \n",
    "model.add(Conv2D(384, (3, 3), strides=1, activation='relu', padding='same'))\n",
    "    \n",
    "model.add(Conv2D(384, (3, 3), strides=1, activation='relu', padding='same'))\n",
    "    \n",
    "model.add(Conv2D(256, (3, 3), strides=1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marci\\AppData\\Local\\Temp\\ipykernel_7028\\2331232953.py:3: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = tf.keras.applications.MobileNetV2(input_shape=(512, 512, 3),\n"
     ]
    }
   ],
   "source": [
    "# MOBILE NET PRÉ-TREINADO\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(512, 512, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "base_model.trainable = False  # Congelar as camadas do modelo base\n",
    "\n",
    "model2 = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m957s\u001b[0m 7s/step - accuracy: 0.6908 - loss: 0.7963 - val_accuracy: 0.7343 - val_loss: 0.5816\n",
      "Epoch 2/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m929s\u001b[0m 7s/step - accuracy: 0.7448 - loss: 0.5716 - val_accuracy: 0.7343 - val_loss: 0.5790\n",
      "Epoch 3/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m939s\u001b[0m 7s/step - accuracy: 0.7276 - loss: 0.5902 - val_accuracy: 0.7343 - val_loss: 0.5870\n",
      "Epoch 4/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m926s\u001b[0m 7s/step - accuracy: 0.7225 - loss: 0.5968 - val_accuracy: 0.7343 - val_loss: 0.5808\n",
      "Epoch 5/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m929s\u001b[0m 7s/step - accuracy: 0.7433 - loss: 0.5712 - val_accuracy: 0.7343 - val_loss: 0.5818\n",
      "Epoch 6/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m937s\u001b[0m 7s/step - accuracy: 0.7255 - loss: 0.5879 - val_accuracy: 0.7343 - val_loss: 0.5789\n",
      "Epoch 7/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m930s\u001b[0m 7s/step - accuracy: 0.7273 - loss: 0.5890 - val_accuracy: 0.7343 - val_loss: 0.5789\n",
      "Epoch 8/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m931s\u001b[0m 7s/step - accuracy: 0.7265 - loss: 0.5872 - val_accuracy: 0.7343 - val_loss: 0.5789\n",
      "Epoch 9/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m933s\u001b[0m 7s/step - accuracy: 0.7284 - loss: 0.5877 - val_accuracy: 0.7343 - val_loss: 0.5813\n",
      "Epoch 10/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m934s\u001b[0m 7s/step - accuracy: 0.7344 - loss: 0.5818 - val_accuracy: 0.7343 - val_loss: 0.5790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1975af70f10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TREINO ALEXNET\n",
    "\n",
    "board = TensorBoard(log_dir='./logsAlex')\n",
    "model.fit(dataTrain, classTrain, batch_size = 32, epochs = 10, validation_data = (dataTest, classTest), callbacks=[board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 5s/step - accuracy: 0.6459 - loss: 20.1427 - val_accuracy: 0.7343 - val_loss: 1.9548\n",
      "Epoch 2/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m587s\u001b[0m 5s/step - accuracy: 0.7291 - loss: 0.6325 - val_accuracy: 0.7343 - val_loss: 4.0500\n",
      "Epoch 3/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m598s\u001b[0m 5s/step - accuracy: 0.7255 - loss: 0.6035 - val_accuracy: 0.7343 - val_loss: 4.1849\n",
      "Epoch 4/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m593s\u001b[0m 5s/step - accuracy: 0.7276 - loss: 0.5897 - val_accuracy: 0.7343 - val_loss: 1.4946\n",
      "Epoch 5/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m594s\u001b[0m 5s/step - accuracy: 0.7171 - loss: 0.5951 - val_accuracy: 0.7343 - val_loss: 0.5794\n",
      "Epoch 6/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m593s\u001b[0m 5s/step - accuracy: 0.7258 - loss: 0.5868 - val_accuracy: 0.7343 - val_loss: 0.5790\n",
      "Epoch 7/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m594s\u001b[0m 5s/step - accuracy: 0.7355 - loss: 0.5786 - val_accuracy: 0.7343 - val_loss: 0.5789\n",
      "Epoch 8/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 5s/step - accuracy: 0.7343 - loss: 0.5791 - val_accuracy: 0.7343 - val_loss: 0.5789\n",
      "Epoch 9/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 5s/step - accuracy: 0.7384 - loss: 0.5759 - val_accuracy: 0.7343 - val_loss: 0.5790\n",
      "Epoch 10/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 5s/step - accuracy: 0.7211 - loss: 0.5920 - val_accuracy: 0.7343 - val_loss: 0.5789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a1e1c9cf10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board2 = TensorBoard(log_dir='./logsShallow')\n",
    "classifier.fit(dataTrain, classTrain, batch_size = 32, epochs = 10, validation_data = (dataTest, classTest), callbacks=[board2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marci\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses\\losses.py:22: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n",
      "C:\\Users\\marci\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:559: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 3s/step - accuracy: 0.2842 - loss: 0.0000e+00 - val_accuracy: 0.2657 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 3s/step - accuracy: 0.2734 - loss: 0.0000e+00 - val_accuracy: 0.2657 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 3s/step - accuracy: 0.2716 - loss: 0.0000e+00 - val_accuracy: 0.2657 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 3s/step - accuracy: 0.2690 - loss: 0.0000e+00 - val_accuracy: 0.2657 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 3s/step - accuracy: 0.2718 - loss: 0.0000e+00 - val_accuracy: 0.2657 - val_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 3s/step - accuracy: 0.2754 - loss: 0.0000e+00 - val_accuracy: 0.2657 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 3s/step - accuracy: 0.2679 - loss: 0.0000e+00 - val_accuracy: 0.2657 - val_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 3s/step - accuracy: 0.2680 - loss: 0.0000e+00 - val_accuracy: 0.2657 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 3s/step - accuracy: 0.2732 - loss: 0.0000e+00 - val_accuracy: 0.2657 - val_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 3s/step - accuracy: 0.2708 - loss: 0.0000e+00 - val_accuracy: 0.2657 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a1351f4f10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board3 = TensorBoard(log_dir='./logsMobile')\n",
    "model2.fit(dataTrain, classTrain, batch_size = 32, epochs = 10, validation_data = (dataTest, classTest), callbacks=[board3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('AlexNet10ep.weights.h5')\n",
    "#model2.save_weights('mobileNet10ep.weights.h5')\n",
    "#classifier.save_weights('shallownet.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marci\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 34 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n",
      "C:\\Users\\marci\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Carregando pesos\n",
    "\n",
    "model.load_weights('AlexNet10ep.weights.h5')\n",
    "classifier.load_weights('shallownet.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 2s/step\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 660ms/step\n"
     ]
    }
   ],
   "source": [
    "npData = np.array(data)\n",
    "alexPredict = model.predict(npData)\n",
    "shallowPredict = classifier.predict(npData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74711275]\n",
      " [0.747967  ]\n",
      " [0.7496995 ]\n",
      " ...\n",
      " [0.7487219 ]\n",
      " [0.7488048 ]\n",
      " [0.7477565 ]]\n",
      "-----------------\n",
      "[[0.72962284]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " ...\n",
      " [0.72962284]\n",
      " [0.72962284]\n",
      " [1.        ]]\n"
     ]
    }
   ],
   "source": [
    "npAlex = np.array(alexPredict)\n",
    "npShallow = np.array(shallowPredict)\n",
    "\n",
    "print(npAlex)\n",
    "print('-----------------')\n",
    "print(npShallow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexClass = (npAlex >= 0.7343).astype(int)\n",
    "ShallowClass = (npShallow >= 0.7343).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "[0 1 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "AlexClass = np.ravel(AlexClass)\n",
    "ShallowClass = np.ravel(ShallowClass)\n",
    "print(AlexClass)\n",
    "print(ShallowClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alex 5100\n",
      "shallow 3559\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "count2 = 0\n",
    "for i in range(len(AlexClass)):\n",
    "    if AlexClass[i] == 1:\n",
    "        count += 1\n",
    "    \n",
    "    if ShallowClass[i] == 1:\n",
    "        count2 += 1\n",
    "\n",
    "print('alex',count)\n",
    "print('shallow',count2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
