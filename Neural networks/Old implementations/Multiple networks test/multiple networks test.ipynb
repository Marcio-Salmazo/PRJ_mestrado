{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras import layers, models, optimizers, losses\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import os \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100\n",
      "(5100, 1)\n"
     ]
    }
   ],
   "source": [
    "# CARREGAMENTO DOS DATASETS\n",
    "\n",
    "''' \n",
    "    Carregando a pasta de imagens (Dataset dos ovos)\n",
    "    * A função glob encontra todos os nomes de caminhos que correspondem a um padrão \n",
    "      especificado de acordo com as regras usadas pelo shell Unix\n",
    "\n",
    "    * Para cada um dos arquivos encontrados é feita a leitura\n",
    "      do arquivo .jpg (imagem), as imagens lidas são armazenadas\n",
    "      na lista 'data'\n",
    "'''\n",
    "img_dir = \"C:/Users/marci/Desktop/Projeto mestrado/Images Dataset/Batch 06.04 Images\"\n",
    "data_path = os.path.join(img_dir,'*g') \n",
    "\n",
    "folder = glob.glob(data_path) \n",
    "data = [] \n",
    "for files in folder: \n",
    "    img = cv2.imread(files) \n",
    "    data.append(img) \n",
    "\n",
    "'''   \n",
    "    Carregando e tratando o arquivo CSV\n",
    "'''\n",
    "eggClass = pd.read_csv(\"RealData.csv\")\n",
    "cList = eggClass.to_numpy()\n",
    "\n",
    "print(len(data))\n",
    "print(cList.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = []\n",
    "values = []\n",
    "for i in range(len(cList)):\n",
    "    if cList[i] == 0:\n",
    "        subset.append(i)\n",
    "    if cList[i] == 1:\n",
    "        values.append(i)\n",
    "\n",
    "randomIndex = np.random.choice(values, 1373, replace=False)\n",
    "\n",
    "for j in range(len(randomIndex)):\n",
    "    subset.append(randomIndex[j])\n",
    "\n",
    "print(subset)\n",
    "print(len(subset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1 = 0\n",
    "ct2 = 0\n",
    "for z in range(len(subset)):\n",
    "    if cList[subset[z]] == 0:\n",
    "        ct1 += 1\n",
    "    if cList[subset[z]] == 1:\n",
    "        ct2 += 1\n",
    "    \n",
    "print(ct1)\n",
    "print(ct2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Completo\n",
    "# Comentar seção caso não seja necessário\n",
    "\n",
    "#ind = np.arange(len(data))\n",
    "train, test = train_test_split(subset, test_size=0.2, random_state=42)\n",
    "\n",
    "#\n",
    "dataTrain = []\n",
    "dataTest = []\n",
    "classTrain = []\n",
    "classTest = []\n",
    "\n",
    "#\n",
    "for i in range(len(train)):\n",
    "\n",
    "    dataTrain.append(data[train[i]])\n",
    "    classTrain.append(cList[train[i]])\n",
    "\n",
    "for j in range(len(test)):\n",
    "\n",
    "    dataTest.append(data[test[j]])\n",
    "    classTest.append(cList[test[j]])\n",
    "\n",
    "#\n",
    "dataTrain = np.array(dataTrain)\n",
    "dataTest = np.array(dataTest)\n",
    "classTrain = np.array(classTrain)\n",
    "classTest = np.array(classTest)\n",
    "\n",
    "print('img train', len(dataTrain))\n",
    "print('img test', len(dataTest))\n",
    "print('class train', len(classTrain))\n",
    "print('class test', len(classTest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "del cList\n",
    "del subset\n",
    "del values\n",
    "del randomIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Alterando o tipo dos dados para float32 a fim de aplicar \n",
    "    a normalização futuramente\n",
    "'''\n",
    "\n",
    "dataTrain = dataTrain.astype('float32')\n",
    "dataTest = dataTest.astype('float32')\n",
    "\n",
    "'''\n",
    "    Realizando a normalização (min/max normalization) a fim de que os valores dos pixels estejam\n",
    "    entre 0 e 1, tornando o processamento mais eficiente\n",
    "    obs: 255 é o valor máximo do pixel\n",
    "'''\n",
    "\n",
    "dataTrain /= 255\n",
    "dataTest /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marci\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# SHALLOW NETWORK\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), input_shape = (512, 512, 3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ALEXNET\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(96, (11, 11), strides=4, activation='relu', input_shape = (512, 512, 3), padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    \n",
    "model.add(Conv2D(256, (5, 5), strides=1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    \n",
    "model.add(Conv2D(384, (3, 3), strides=1, activation='relu', padding='same'))\n",
    "    \n",
    "model.add(Conv2D(384, (3, 3), strides=1, activation='relu', padding='same'))\n",
    "    \n",
    "model.add(Conv2D(256, (3, 3), strides=1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREINO ALEXNET\n",
    "\n",
    "board = TensorBoard(log_dir='./logs30AlexSubset50x50')\n",
    "model.fit(dataTrain, classTrain, batch_size = 32, epochs = 30, validation_data = (dataTest, classTest), callbacks=[board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREINO SHALLOWNET\n",
    "\n",
    "board2 = TensorBoard(log_dir='./logsShallow')\n",
    "classifier.fit(dataTrain, classTrain, batch_size = 32, epochs = 10, validation_data = (dataTest, classTest), callbacks=[board2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('AlexNet30Subset50x50.weights.h5')\n",
    "#model2.save_weights('mobileNet10ep.weights.h5')\n",
    "#classifier.save_weights('shallownet.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 33 variables. \n"
     ]
    }
   ],
   "source": [
    "# Carregando pesos\n",
    "\n",
    "model.load_weights('AlexNet30Subset50x50.weights.h5')\n",
    "#classifier.load_weights('shallownet.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 168s 1s/step\n"
     ]
    }
   ],
   "source": [
    "npData = np.array(data)\n",
    "alexPredict = model.predict(npData)\n",
    "#shallowPredict = classifier.predict(npData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.805369  ]\n",
      " [0.8288535 ]\n",
      " [0.83847976]\n",
      " ...\n",
      " [0.813279  ]\n",
      " [0.8383563 ]\n",
      " [0.8837195 ]]\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "npAlex = np.array(alexPredict)\n",
    "#npShallow = np.array(shallowPredict)\n",
    "\n",
    "print(npAlex)\n",
    "print('-----------------')\n",
    "#print(npShallow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3728\n",
      "0.73\n"
     ]
    }
   ],
   "source": [
    "groundTruth = np.ravel(cList)\n",
    "maxValue = 0\n",
    "thresh = 0\n",
    "\n",
    "for i in np.arange(0, 1.00, 0.01):\n",
    "    AlexClass = (npAlex >= i).astype(int)\n",
    "    AlexClass = np.ravel(AlexClass)\n",
    "    hits = 0\n",
    "\n",
    "    for j in range(len(groundTruth)):\n",
    "        if AlexClass[j] == groundTruth[j]:\n",
    "            hits += 1\n",
    "\n",
    "    if hits >= maxValue:\n",
    "        maxValue = hits\n",
    "        thresh = i\n",
    "    \n",
    "print(maxValue)\n",
    "print(thresh)   \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "AlexClass = (npAlex >= 0.5).astype(int)\n",
    "#ShallowClass = (npShallow >= 0.5).astype(int)\n",
    "AlexClass = np.ravel(AlexClass)\n",
    "#ShallowClass = np.ravel(ShallowClass)\n",
    "print(AlexClass)\n",
    "#print(ShallowClass)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
