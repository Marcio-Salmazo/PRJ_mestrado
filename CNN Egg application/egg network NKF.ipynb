{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential  # Modelo sequencial\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras import utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import os \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dataTrain: (4080, 512, 512, 3)\n",
      "Shape dataTest: (1020, 512, 512, 3)\n",
      "Shape classTrain: (4080, 1)\n",
      "Shape classTest: (1020, 1)\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "    Carregando a pasta de imagens (Dataset dos ovos)\n",
    "    * A função glob encontra todos os nomes de caminhos que correspondem a um padrão \n",
    "      especificado de acordo com as regras usadas pelo shell Unix\n",
    "\n",
    "    * Para cada um dos arquivos encontrados é feita a leitura\n",
    "      do arquivo .jpg (imagem), as imagens lidas são armazenadas\n",
    "      na lista 'data'\n",
    "'''\n",
    "\n",
    "img_dir = \"C:/Users/marci/Desktop/Projeto mestrado/CNN Egg application/Egg Dataset\"\n",
    "data_path = os.path.join(img_dir,'*g') \n",
    "\n",
    "folder = glob.glob(data_path) \n",
    "data = [] \n",
    "for files in folder: \n",
    "    img = cv2.imread(files) \n",
    "    data.append(img) \n",
    "\n",
    "eggData = np.array(data)\n",
    "eggClass = pd.read_csv(\"resultado Fake.csv\")\n",
    "\n",
    "dataTrain, dataTest = train_test_split(eggData, test_size=0.2) \n",
    "classTrain, classTest = train_test_split(eggClass, test_size=0.2)\n",
    "\n",
    "print('Shape dataTrain:', dataTrain.shape)\n",
    "print('Shape dataTest:', dataTest.shape)\n",
    "print('Shape classTrain:', classTrain.shape)\n",
    "print('Shape classTest:', classTest.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dataTrain: (4080, 512, 512, 3)\n",
      "Shape classTrain: (4080, 1)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Alterando o tipo dos dados para float32 a fim de aplicar \n",
    "    a normalização futuramente\n",
    "'''\n",
    "\n",
    "dataTrain = dataTrain.astype('float32')\n",
    "dataTest = dataTest.astype('float32')\n",
    "\n",
    "'''\n",
    "    Realizando a normalização (min/max normalization) a fim de que os valores dos pixels estejam\n",
    "    entre 0 e 1, tornando o processamento mais eficiente\n",
    "    obs: 255 é o valor máximo do pixel\n",
    "'''\n",
    "\n",
    "dataTrain /= 255\n",
    "dataTest /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "   Definição da rede neural convolucional\n",
    "\n",
    "    * Criação da cnn no modelo sequencial (sequencia de layers)\n",
    "    * Criação de duas camadas de convolução com função de ativação Relu, \n",
    "      seguidas pelos processos de normalização dos mapas de características e max Pooling.\n",
    "      O processo de flattening é adicionado ao final das camadas. \n",
    "'''\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), input_shape = (512, 512, 3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "'''\n",
    "    * Adição das hidden Layers\n",
    "    * Aplicação da operação de dropout às saídas \n",
    "        Busca zerar uma determinada quantidade de entradas \n",
    "        a fim de otimizar o sistema e reduzir o overfitting\n",
    "    * Adição da camada de saída, utilizando a sigmóide como função de ativação\n",
    "        A sigmóide é utilzada em classificações binárias\n",
    "        OBS -> units = 1 indica que há apenas uma unidade de saída para\n",
    "        a classificação binária\n",
    "'''\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "'''\n",
    "    * Compilação da rede neural\n",
    "        OBS: Para a classificação binária, a função de perda será definida \n",
    "        por 'binary_crossentropy'. Para a classificação em múltiplas classes\n",
    "        é necessário utilizar o 'categorical_crossentropy'\n",
    "'''\n",
    "\n",
    "classifier.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "ename": "AbortedError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n\n  File \"C:\\Users\\marci\\AppData\\Local\\Temp\\ipykernel_7244\\7978591.py\", line 23, in <module>\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1154, in train_step\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 543, in minimize\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 276, in compute_gradients\n\nCompute received an exception:Status:1, message: could not create a memory object. in file tensorflow/core/kernels/mkl/mkl_maxpooling_op.cc:388\n\t [[{{node gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad}}]] [Op:__inference_train_function_2151]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAbortedError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 23\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m''' \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m    Etapa de treinamento da rede neural. É importante que a função 'fit_generator' está sendo\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    utilizada ao invés da função 'fit' uma vez que ela suporta o processo de augmentation, contudo\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m                          se dá pelo total de amostras dividido pel valor do batch_size\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataTrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassTrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataTest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassTest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAbortedError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n\n  File \"C:\\Users\\marci\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n\n  File \"C:\\Users\\marci\\AppData\\Local\\Temp\\ipykernel_7244\\7978591.py\", line 23, in <module>\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1154, in train_step\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 543, in minimize\n\n  File \"c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 276, in compute_gradients\n\nCompute received an exception:Status:1, message: could not create a memory object. in file tensorflow/core/kernels/mkl/mkl_maxpooling_op.cc:388\n\t [[{{node gradient_tape/sequential/max_pooling2d/MaxPool/MaxPoolGrad}}]] [Op:__inference_train_function_2151]"
     ]
    }
   ],
   "source": [
    "''' \n",
    "    Etapa de treinamento da rede neural. É importante que a função 'fit_generator' está sendo\n",
    "    utilizada ao invés da função 'fit' uma vez que ela suporta o processo de augmentation, contudo\n",
    "    tal função está em processo de depreciação, uma vez que em versões mais atuais, a função 'fit' \n",
    "    também suporta.\n",
    "\n",
    "    Explicação dos parâmetros:\n",
    "\n",
    "    * trainDatabase -> Dados para treino (após a augmentation)\n",
    "    * steps_per_epoch -> Número total de etapas (lotes de amostras) a serem produzidas \n",
    "                         pelo gerador antes de declarar uma época concluída e iniciar a próxima época.\n",
    "                         É importante citar que o valor ideal para este parâmetro se dá pela quantidade \n",
    "                         total de imagens para treinamento (caso haja um alto poder de processamento) ou\n",
    "                         pelo total de amostras dividido pel valor do batch_size (caso haja um baixo \n",
    "                         poder de processamento)\n",
    "    * epochs -> Epocas de treinamento da rede\n",
    "    * validation_data -> Dados para a validação (após a augmentation)\n",
    "    * validation_steps -> Possui o mesmo princípio do 'steps_per_epoch', porém levando em \n",
    "                          consideração a etapa de validação. O valor ideal para este parâmetro \n",
    "                          se dá pelo total de amostras dividido pel valor do batch_size\n",
    "'''\n",
    "\n",
    "classifier.fit(dataTrain, classTrain, batch_size = 128, epochs = 5, validation_data = (dataTest, classTest))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
