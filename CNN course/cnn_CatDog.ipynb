{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential  # Modelo sequencial\n",
    "from keras.layers import Dense, Flatten  # 3ª e 4ª etapa da CNN\n",
    "from keras.layers import Conv2D, MaxPooling2D  # 1ª e 2ª etapa da CNN\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "   Definição da rede neural convolucional\n",
    "\n",
    "    * Criação da cnn no modelo sequencial (sequencia de layers)\n",
    "    * Criação de duas camadas de convolução com função de ativação Relu, \n",
    "      seguidas pelos processos de normalização dos mapas de características e max Pooling.\n",
    "      O processo de flattening é adicionado ao final das camadas. \n",
    "'''\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "'''\n",
    "    * Adição das hidden Layers\n",
    "    * Aplicação da operação de dropout às saídas \n",
    "        Busca zerar uma determinada quantidade de entradas \n",
    "        a fim de otimizar o sistema e reduzir o overfitting\n",
    "    * Adição da camada de saída, utilizando a sigmóide como função de ativação\n",
    "        A sigmóide é utilzada em classificações binárias\n",
    "        OBS -> units = 1 indica que há apenas uma unidade de saída para\n",
    "        a classificação binária\n",
    "'''\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 1, activation = 'softmax'))\n",
    "\n",
    "'''\n",
    "    * Compilação da rede neural\n",
    "        OBS: Para a classificação binária, a função de perda será definida \n",
    "        por 'binary_crossentropy'. Para a classificação em múltiplas classes\n",
    "        é necessário utilizar o 'categorical_crossentropy'\n",
    "'''\n",
    "\n",
    "classifier.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Geração das novas imagens, pelo processo de augmentation\n",
    "    generatedTrain e generatedTest contém as definições \n",
    "    de como as imagens serão modificadas pelo Image data Generator \n",
    "    \n",
    "    OBS: O parâmetro 'rescale' do ImageDataGenerator realiza o \n",
    "    processo de normalização de modo automático\n",
    "'''\n",
    "generatedTrain = ImageDataGenerator(rescale = 1./255,\n",
    "                                    rotation_range = 7,\n",
    "                                    horizontal_flip = True,\n",
    "                                    shear_range = 0.2,\n",
    "                                    height_shift_range = 0.07,\n",
    "                                    zoom_range = 0.2)\n",
    "\n",
    "generatedTest = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "'''\n",
    "    A base de dados para o treinamento é criada, utilizando o método flow_from_directory nas \n",
    "    variáveis generatedTrain e generatedTest a fim de buscar o dataset armazenado em um determinado \n",
    "    diretório e aplicar as definições descritas previamentes pela classe ImageDataGenerator.\n",
    "\n",
    "    * Descrição dos parâmetros utilizados no método flow_from_directory:\n",
    "    * 'dataset_catDog/training_set' -> Descreve o caminho para o dataset \n",
    "    * target_size -> Descreve o tamanho das imagens para entrada\n",
    "    * batch_size -> Define o número de amostras que serão propagadas pela rede\n",
    "    * class_mode -> Define a forma de classificação (As classes são definidas pelas pastas presentes no dataset)\n",
    "'''\n",
    "\n",
    "trainDatabase = generatedTrain.flow_from_directory('dataset_catDog/training_set', \n",
    "                                                   target_size = (64,64), \n",
    "                                                   batch_size = 32, \n",
    "                                                   class_mode = 'binary')\n",
    "\n",
    "testDatabase = generatedTest.flow_from_directory('dataset_catDog/test_set', \n",
    "                                                   target_size = (64,64), \n",
    "                                                   batch_size = 32, \n",
    "                                                   class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marci\\AppData\\Local\\Temp\\ipykernel_13972\\1269131039.py:23: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(trainDatabase,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "125/125 [==============================] - 38s 290ms/step - loss: 0.7914 - accuracy: 0.5000 - val_loss: 0.8050 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.6596 - accuracy: 0.5000 - val_loss: 0.6789 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.6264 - accuracy: 0.5000 - val_loss: 0.7353 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 12s 94ms/step - loss: 0.5995 - accuracy: 0.5000 - val_loss: 0.6063 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.5736 - accuracy: 0.5000 - val_loss: 0.5903 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c31f9cd8d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "    Etapa de treinamento da rede neural. É importante que a função 'fit_generator' está sendo\n",
    "    utilizada ao invés da função 'fit' uma vez que ela suporta o processo de augmentation, contudo\n",
    "    tal função está em processo de depreciação, uma vez que em versões mais atuais, a função 'fit' \n",
    "    também suporta.\n",
    "\n",
    "    Explicação dos parâmetros:\n",
    "\n",
    "    * trainDatabase -> Dados para treino (após a augmentation)\n",
    "    * steps_per_epoch -> Número total de etapas (lotes de amostras) a serem produzidas \n",
    "                         pelo gerador antes de declarar uma época concluída e iniciar a próxima época.\n",
    "                         É importante citar que o valor ideal para este parâmetro se dá pela quantidade \n",
    "                         total de imagens para treinamento (caso haja um alto poder de processamento) ou\n",
    "                         pelo total de amostras dividido pel valor do batch_size (caso haja um baixo \n",
    "                         poder de processamento)\n",
    "    * epochs -> Epocas de treinamento da rede\n",
    "    * validation_data -> Dados para a validação (após a augmentation)\n",
    "    * validation_steps -> Possui o mesmo princípio do 'steps_per_epoch', porém levando em \n",
    "                          consideração a etapa de validação. O valor ideal para este parâmetro \n",
    "                          se dá pelo total de amostras dividido pel valor do batch_size\n",
    "'''\n",
    "\n",
    "classifier.fit_generator(trainDatabase, \n",
    "                         steps_per_epoch = 4000/32, \n",
    "                         epochs = 5, \n",
    "                         validation_data = testDatabase,\n",
    "                         validation_steps = 1000/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[1.]]\n",
      "{'cachorro': 0, 'gato': 1}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Previsões feitas com uma determinada imagem\n",
    "    Uma imagem é passada como entrada e o retorno será a sua classificação\n",
    "\n",
    "    Explicação dos processos:\n",
    "    \n",
    "    * image.load_img() -> A imagem para previsão é carregada no sistema e o valor de suas dimensões é definido\n",
    "    * image.img_to_array() -> A imagem tem o seu tipo alterado para um Array\n",
    "    * testImage /= 255 -> Os valores do array são normalizados\n",
    "    * np.expand_dims() -> Há uma expansão das dimensões da imagem\n",
    "        dimensões originais - (64,64,3) -> largura, altura, canais\n",
    "        dimensões transformadas - (1,64,64,3) -> batch, largura, altura, canais\n",
    "    * classifier.predict() -> Realiza a previsão, o retorno sera um float entre 0 e 1, indicando a \n",
    "        probabilidade de pertencer à classe 0 ou à classe 0 (Essa estrutura advém da sigmóide)\n",
    "    * trainDatabase.class_indices -> Exibe qual valor está atribuído a qual classe, neste caso temos:\n",
    "        0 - cachorro\n",
    "        1 - gato\n",
    "\n",
    "    * OBS -> Neste caso, a imagem carregada será a de uma gato\n",
    "'''\n",
    "testImage = image.load_img('dataset_catDog/test_set/gato/cat.3513.jpg', target_size = (64,64))\n",
    "testImage = image.img_to_array(testImage)\n",
    "testImage /= 255\n",
    "testImage = np.expand_dims(testImage, axis = 0)\n",
    "\n",
    "prev = classifier.predict(testImage)\n",
    "print(prev)\n",
    "print(trainDatabase.class_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
