{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Classificação de digitos escritos à mão com o uso da CNN\n",
    "    Atividade do curso 'Deep Learning com Python de A a Z - O Curso Completo'\n",
    "    Marcio Salmazo Ramos\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist  # Importação da base de dados\n",
    "from keras.models import Sequential  # Modelo sequencial\n",
    "from keras.layers import Dense, Flatten  # 3ª e 4ª etapa da CNN\n",
    "from keras.layers import Conv2D, MaxPooling2D  # 1ª e 2ª etapa da CNN\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Realizando o tratamento de dados no Dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos atributos previsores de teste (10000, 28, 28)\n",
      "Shape dos atributos previsores de treinamento (60000, 28, 28)\n",
      "Shape das classes de teste (10000,)\n",
      "Shape das classes de treinamento (60000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    Existem 60000 imagens para treinamento 28x28 px\\n    Existem 10000 imagens para teste 28x28 px\\n    Existem 10000 valores como resposta para as imagens de teste\\n    Existem 60000 valores como resposta para as imagens de treinamento\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Carregar a base de dados, já com a separação pré-definida para teste e treinamento\n",
    "    x -> atributos previsores\n",
    "    y -> classes da base\n",
    "'''\n",
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "sizeXTRAIN = xTrain.shape\n",
    "sizeXTEST = xTest.shape\n",
    "sizeYTRAIN = yTrain.shape\n",
    "sizeYTEST = yTest.shape\n",
    "\n",
    "print('Shape dos atributos previsores de teste', sizeXTEST)\n",
    "print('Shape dos atributos previsores de treinamento', sizeXTRAIN)\n",
    "print('Shape das classes de teste', sizeYTEST)\n",
    "print('Shape das classes de treinamento', sizeYTRAIN)\n",
    "\n",
    "'''\n",
    "    Existem 60000 imagens para treinamento 28x28 px\n",
    "    Existem 10000 imagens para teste 28x28 px\n",
    "    Existem 10000 valores como resposta para as imagens de teste\n",
    "    Existem 60000 valores como resposta para as imagens de treinamento\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    É necessário realizar uma transformação dos dados a fim de que o tensorflow\n",
    "    consiga analizá-los. Neste caso, a dimensionalidade de cada imagem será diminuida,\n",
    "    ou seja, apenas uma camada RGB será utilizada \n",
    "'''\n",
    "trainForecasters = xTrain.reshape(xTrain.shape[0], 28, 28, 1)\n",
    "testForecasters = xTest.reshape(xTest.shape[0], 28, 28, 1)\n",
    "\n",
    "'''\n",
    "    Alterando o tipo dos dados para float32 a fim de aplicar \n",
    "    a normalização futuramente\n",
    "'''\n",
    "\n",
    "trainForecasters = trainForecasters.astype('float32')\n",
    "testForecasters = testForecasters.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Realizando a normalização (min/max normalization) a fim de que os valores dos pixels estejam\n",
    "    entre 0 e 1, tornando o processamento mais eficiente\n",
    "    obs: 255 é o valor máximo do pixel\n",
    "'''\n",
    "\n",
    "trainForecasters /= 255\n",
    "testForecasters /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Criação de dummy variables a fim de criar um encoder para \n",
    "    os diferentes valores.\n",
    "    Uma variável Dummy é aquela que toma o valor de \"zero\" ou \"um\" \n",
    "    indicando a ausência ou presença de qualidades ou atributos. \n",
    "    Essas variáveis são usadas como dispositivos para classificar \n",
    "    dados em categorias mutuamente exclusivas.\n",
    "\n",
    "    Esta etapa se faz necessária, uma vez que o problema exige \n",
    "    classificação em mais de duas classes\n",
    "\n",
    "    Com método utils.to_categorical no keras, um array de valores\n",
    "    inteiro que representem diferentes classes pode ser convertido em\n",
    "    um array ou matriz de valores binários que representem os inteiros \n",
    "    no array original, exemplo:\n",
    "\n",
    "    Arr = <1,2,3,4>\n",
    "    Mat = utils.to_categorical(Arr, 4)\n",
    "\n",
    "    Mat = <\n",
    "        <0,0,0,1>\n",
    "        <0,0,1,0>\n",
    "        <0,0,1,1>\n",
    "        <0,1,0,0>\n",
    "    >\n",
    "'''\n",
    "trainClass = utils.to_categorical(yTrain, 10)\n",
    "testClass = utils.to_categorical(yTest, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Aplicando a rede neural densa</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Aplicando o operador de convolução\n",
    "    A variável 'classifier recebe o modelo sequencial, ou seja: \n",
    "    permite inserir camadas de uma rede neural em série, onde o output da primeira \n",
    "    camada serve como input da segunda, e assim por diante.'\n",
    "\n",
    "    A primeira camada (referência à imagem) contém o resultado do operador de \n",
    "    convolução. Neste caso, é definido que serão utilizados 32 filtros ou\n",
    "    detectores de características para cada convolução e o kernal utilizado\n",
    "    será 3x3. Por fim, a função de ativação para cada convolução será o Relu\n",
    "\n",
    "    A função batch_normalization realiza a normalização do valores \n",
    "    do mapa de características gerado. Dessa forma há uma otimização\n",
    "    no processo\n",
    "'''\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Criação de uma nova camada de convolução, seguindo os mesmos\n",
    "    moldes das etapas anteriores (operador convolução, pooling e flattening)\n",
    "'''\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    A terceira etapa se dá apenas pelo achatamento da matriz\n",
    "    obtido após o processo de pooling na etapa anterior\n",
    "    \n",
    "    Obs: o flattening precisa ser aplicado apenas ao final de \n",
    "    todas as camadas de convolução\n",
    "'''\n",
    "\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    A quarta etapa do processo se dá pela adição da rede neural densa\n",
    "    tendo como entrada os valores provenientes do vetor obtido na \n",
    "    etapa anterior.\n",
    "\n",
    "    Nesta implementação, a rede neural conta com duas camadas\n",
    "    intermediárias contendo 128 neurônios, e para cada um de seus \n",
    "    neurônios a função de ativação será a função Relu. Além disso,\n",
    "    também é definida a camada de saída (contendo 10 saídas) e tem \n",
    "    a função 'softmax' como função de ativação \n",
    "\n",
    "    A função Dropout serve para zerar uma determinada quantidade de \n",
    "    entradas a fim de otimizar o sistema e reduzir o overfitting, \n",
    "    uma vez que neste caso a quantidade de inputs é expressiva.\n",
    "    Neste caso (0.2) 20% das entradas serão zeradas \n",
    "'''\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units = 10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "469/469 [==============================] - 13s 23ms/step - loss: 0.2042 - accuracy: 0.9361 - val_loss: 0.1438 - val_accuracy: 0.9574\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0628 - accuracy: 0.9813 - val_loss: 0.0353 - val_accuracy: 0.9894\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0446 - accuracy: 0.9867 - val_loss: 0.0404 - val_accuracy: 0.9859\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0373 - accuracy: 0.9886 - val_loss: 0.0326 - val_accuracy: 0.9893\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 0.0351 - val_accuracy: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x270c8319fd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    A rede criada será compilada. Para a função de custo é utilizada a categorical_crossentropy\n",
    "    (também conhecida como 'softmax loss'), ela é utilizada quando a saída é composta por \n",
    "    múltiplas classes (neste caso temos as possibilidades de 1 a 10)\n",
    "\n",
    "    O otimizador 'adam' trata-se de um método estocástico de descida gradiente baseado na estimativa \n",
    "    adaptativa de momentos de primeira e segunda ordem\n",
    "\n",
    "    O parâmetro metrics calcula com que frequência as previsões são iguais aos rótulos. \n",
    "    Essa métrica cria duas variáveis locais, 'total' e 'count' para calcular a frequência com que \n",
    "    a previsão corresponde ao gabarito.\n",
    "'''\n",
    "classifier.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "'''\n",
    "    O método fit no Keras é responsável por efetuar o treinamento do modelo, nele serão passados como\n",
    "    parâmetros:\n",
    "\n",
    "    * Os dados previsores e suas respectivas classes para o treinamento\n",
    "    * O 'batch_size' que define o número de amostras que serão propagadas pela rede, por exemplo:\n",
    "        Supondo que haja 1.050 amostras de treinamento e queira configurar um batch_size igual a 100. \n",
    "        O algoritmo pega as primeiras 100 amostras (da 1ª à 100ª) do conjunto de dados de treinamento e treina a rede. \n",
    "        Em seguida, ele pega as segundas 100 amostras (da 101ª à 200ª) e treina a rede novamente.\n",
    "        OBS: o batch_size requer menos uso da memória\n",
    "    \n",
    "    * As épocas indicam o número total de iterações de todos os dados de treinamento em um ciclo \n",
    "        para treinar o modelo de aprendizado de máquina.\n",
    "    * O validation_data traz os dados previsores e suas respectivas classes de teste (para comparação)\n",
    "'''\n",
    "classifier.fit(trainForecasters, trainClass, batch_size = 128, epochs = 5, validation_data = (testForecasters, testClass))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
